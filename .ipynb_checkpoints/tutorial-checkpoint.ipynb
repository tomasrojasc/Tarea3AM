{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import color\n",
    "from skimage.feature import hog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. Importar datos\n",
    "\n",
    "Los datos vienen en un archivo **.json**, con la siguientes llaves:\n",
    "\n",
    "- `data`: list of list[int], imagenes 80x80 RGB, las imagenes estan aplanadas en un vector de dimensión 19200 (80x80x3),  las primeras 6400 entradas contienen los valores del canal rojo, las siguientes 6400 del verde, y las últimas 6400 del azul. La imagen es almacenada en orden fila, asi las primeras 80 entradas del arreglo son los valores del canal rojo de la primera fila de la imagen.\n",
    "- `labels`: list of int, etiquetas de las imágenes, donde 1->\"ship\", 0->\"no-ship\".\n",
    "- `locations`**(irrelevante)**: list of tuples, coordenadas geográficas, longitud y latitude del punto central de cada imágen.\n",
    "- `scene_ids`: list, identificador único de cada imágen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargar datos\n",
    "with open(\"shipsnet.json\", \"r\") as f:\n",
    "    dataset = json.load(f)\n",
    "print(dataset.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llevar las imagenes aplanadas a 80x80x3\n",
    "data = np.array(dataset['data']).astype('uint8')\n",
    "data = data.reshape(-1,3,80,80).transpose([0,2,3,1])\n",
    "labels =  np.array(dataset['labels'])\n",
    "\n",
    "print(f\"Dimensión: {data.shape}\")\n",
    "\n",
    "# ejemplos\n",
    "plt.imshow(data[51])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " plt.figure(figsize=(10,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplos\n",
    "f = plt.figure(figsize=(16,9))\n",
    "for i in range(1,7):\n",
    "    ax = f.add_subplot(2,6,i)\n",
    "    ax.imshow(data[50+i])\n",
    "for i in range(1,7):\n",
    "    ax = f.add_subplot(1,6,i)\n",
    "    ax.imshow(data[-1-i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llevamos las imágenes RGB a escala de grises\n",
    "data_gray = np.array([color.rgb2gray(i) for i in data])\n",
    "print(f\"Dimensión: {data_gray.shape}\")\n",
    "# ejemplos\n",
    "f = plt.figure(figsize=(16,9))\n",
    "for i in range(1,7):\n",
    "    ax = f.add_subplot(2,6,i)\n",
    "    ax.imshow(data_gray[50+i])\n",
    "for i in range(1,7):\n",
    "    ax = f.add_subplot(1,6,i)\n",
    "    ax.imshow(data_gray[-1-i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. Extracción de características\n",
    "\n",
    "## Histograms of Gradients (HoG) (lectura opcional)\n",
    "\n",
    "EL histograma de orientación de gradiente (HoG) es un descriptor de características usado en visión por computadora y procesamiento de imágenes para la detección de objetos. Su utilidad viene dada de que la magnitud del gradiente es grande alrededor de los bordes y esquinas (regiones con cambios abruptos de itensidad), donde los arcos y esquinas contienen mucha más información sobre la forma del objeto que las regiones planas.\n",
    "\n",
    "Sea $I_{i,j}$ la intensidad del pixel $(i,j)$, luego la magnitud del gradiente y su orientación viene dada por la siguiente expresión:\n",
    "\n",
    "\\begin{align}\n",
    "& g = \\sqrt{g_x^2+g_y^2}, g_x = I_{i,j}-I_{i-1,j}, g_y = I_{i,j}-I_{i,j-1}\\\\\n",
    "& \\theta = \\text{arctan}\\frac{gx}{gy}\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "Así el output inicial del procedemiento son dos matrices, una matriz que contiene la magnitud del gradiente de cada pixel y otra con la orientación del gradiente. Para convertir estas matrices a un vector se utilizará un histograma, por ejemplo, podemos dividir el dominio de las orientaciones en 9 bins de 20° (180° total, no son 360° ya que las transiciones de negro a blanco y de blanco a negro se consideran equivalentes), obteniéndose así un vector de dimensión 9, es decir, [0, 20, 40, 60, 80, 100, 120, 140, 160]. Luego cada pixel de una imágen votará en estos bins en base a la magnitud de gradiente que posee y su cercanía a los bins según su orientación, por ejemplo, si tenemos un pixel con ángulo 10° y magnitud 4, este sumára 2 al bin 0° y 2 al bin 20° pues se encuentra justo a la mitad de ambos, por otro lado, si tenemos un pixel con ángulo 80° y magnitud 2 este sumará solo al bin 80°. \n",
    "\n",
    "<img src=\"hog_histogram.png\">\n",
    "\n",
    "Para capturar de mejor forma información local de la imagen se suele dividir en zonas y calcular HoG en cada una de estas, siendo el vector resultante la concatenación de todos los histogramas. En el ejemplo a continuación la imágen se divide en 4x4 (16 submatrices, viene de dividir 80x80/(20x20)) y para cada zona se calcula HoG con 8 bins. \n",
    "\n",
    "Más detalle en:\n",
    "\n",
    "- https://scikit-image.org/docs/stable/auto_examples/features_detection/plot_hog.html?highlight=hog\n",
    "- https://www.learnopencv.com/histogram-of-oriented-gradients/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extrae hog features y hog transformation para cada imagen\n",
    "ppc = 20\n",
    "hog_images = []\n",
    "hog_features = []\n",
    "for image in data_gray:\n",
    "    fd,hog_image = hog(image, orientations=8, pixels_per_cell=(ppc,ppc), cells_per_block=(1, 1),block_norm= 'L2',visualize=True)\n",
    "    hog_images.append(hog_image)\n",
    "    hog_features.append(fd)\n",
    "hog_features = np.array(hog_features)\n",
    "hog_images = np.array(hog_images)\n",
    "\n",
    "hog_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplos\n",
    "f = plt.figure(figsize=(16,9))\n",
    "for i in range(1,7):\n",
    "    ax = f.add_subplot(2,6,i)\n",
    "    ax.imshow(data_gray[50+i])\n",
    "for i in range(1,7):\n",
    "    ax = f.add_subplot(1,6,i)\n",
    "    ax.imshow(hog_images[50+i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C. División en train-validation-test y métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, train_size=.7, random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, train_size=.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D. Entrenamiento y evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLogisticRegression:\n",
    "    def __init__(self, eta=0.1, epochs=100):\n",
    "        self.eta = eta\n",
    "        self.epochs = epochs\n",
    "    def fit(X, y):\n",
    "        \"\"\"\n",
    "        En base al conjunto de entrenamiento D={X,y}, \n",
    "        despejar w y guardar en un atributo del objeto.\n",
    "        \"\"\"\n",
    "        N, M = X.shape\n",
    "        w = np.zeros(M)\n",
    "        for epoch in range(self.epochs):\n",
    "            for i in range(N):\n",
    "                ...\n",
    "                w = ...\n",
    "        self.w = w\n",
    "    def predict(X):\n",
    "        \"\"\"\n",
    "        Retorna las predicciones sobre X.\n",
    "        \"\"\"\n",
    "        ...\n",
    "        return predictions\n",
    "        \n",
    "    def log_verosimilitud(self, X, y):\n",
    "        \"\"\"\n",
    "        Dado el vector de pesos w retorna la log-verosimilitud\n",
    "        normalizada por el número de observaciones sobre D={X,y}\n",
    "        \"\"\"\n",
    "        ll = ...\n",
    "        return ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crear objeto modelo\n",
    "clf = MyLogisticRegression(eta=0.01)\n",
    "# entrenar\n",
    "clf.fit(X_train, y_train)\n",
    "# computar log-likelihood\n",
    "clf.log_verosimilitud(X_train, y_train)\n",
    "# predecir\n",
    "y_pred = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyFLDA:\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        En base al conjunto de entremamiento D={X,y},\n",
    "        despejar a y b y guardar los atributos del objeto\n",
    "        \"\"\"\n",
    "  \n",
    "        a = ...\n",
    "        b = ...\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Retorna las predicciones sobre X.\n",
    "        \"\"\"\n",
    "        return predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
